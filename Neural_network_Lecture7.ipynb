{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method' : 'grid',\n",
    "    'metric': {\n",
    "        'name' : 'val_accuracy',\n",
    "        'goal' : 'maximize'\n",
    "    },\n",
    "    'parameters' : {\n",
    "        'batch_size' : { 'values' : [8, 16, 32, 64, 128]},\n",
    "        'learning_rate' : { 'values' : [0.001, 0.0001, 0.00001]},\n",
    "        'hidden_nodes': {'values' : [32, 64, 128, 256]},\n",
    "        'img_size' : {'values' : [16, 64, 224]},\n",
    "        'epochs' : {'values': [5, 10]}\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"5-Flower-Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csvline(csv_line):\n",
    "  # print(\"csv line:\", csv_line)\n",
    "  # record_defaults specify the data types for each columns\n",
    "  record_default = [\"\", \"\"]\n",
    "  filename, label_string =tf.io.decode_csv(csv_line, record_defaults=record_default)\n",
    "\n",
    "\n",
    "  #load the image\n",
    "  img= read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  # print(\"Label String:\",label_string)\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  with wandb.init() as run:\n",
    "    config= wandb.config\n",
    "    import tensorflow as tf\n",
    "    IMG_HEIGHT= config.img_size\n",
    "    IMG_WIDTH= config.img_size\n",
    "    IMG_CHANNELS=3\n",
    "    CLASS_NAMES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
    "    def read_and_decode(filename, resize_dims):\n",
    "      # 1. Read the raw file\n",
    "      img_bytes= tf.io.read_file(filename)\n",
    "      # 2. Decode image data\n",
    "      img= tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
    "      # 3. Convert image to float values in [0, 1]\n",
    "      img= tf.image.convert_image_dtype(img, tf.float32)\n",
    "      # 4. Resize the image to the match the desire dimention\n",
    "      img= tf.image.resize(img, resize_dims)\n",
    "      return img\n",
    "\n",
    "    def parse_csvline(csv_line):\n",
    "      # print(\"csv line:\", csv_line)\n",
    "      # record_defaults specify the data types for each columns\n",
    "      record_default = [\"\", \"\"]\n",
    "      filename, label_string =tf.io.decode_csv(csv_line, record_defaults=record_default)\n",
    "\n",
    "\n",
    "      #load the image\n",
    "      img= read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "      # print(\"Label String:\",label_string)\n",
    "      label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "      return img, label\n",
    "\n",
    "    #Define dataset\n",
    "    train_dataset = (\n",
    "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/train_set.csv\")\n",
    "        #.map(parse_csvline) # it will process one by one line to the map function which is slow\n",
    "        #.map(parse_csvline, num_parallel_calls=4) # it will process one by four line to the map function which is faster\n",
    "\n",
    "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE) # It will adjust the number of line to the function depends upon the cpu\n",
    "        .batch(config.batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    test_dataset = (\n",
    "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\")\n",
    "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(config.batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE) # When the model is training the current batch then it will prepare the next batch in the background.\n",
    "    )\n",
    "    # Define the  base model\n",
    "    base_model= tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "\n",
    "    regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "    model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(len(CLASS_NAMES), kernel_regularizer=regularizer),\n",
    "    keras.layers.Activation('softmax')\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=config.epochs,\n",
    "    callbacks=[WandbMetricsLogger(),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True),\n",
    "               ]\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
